{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq4dZebVEfow",
        "outputId": "0ce72882-f64a-4e54-f7c3-bf47a0f87246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ollama colab-xterm -q\n",
        "%load_ext colabxterm\n",
        "\n",
        "#curl https://ollama.ai/install.sh | sh\n",
        "# ollama serve &\n",
        "# ollama pull qwen3-vl:4b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qqCOOoeNTtQ"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQXUDfPHCUnT",
        "outputId": "72cf66c6-5924-4caa-f86c-b57a4af21380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "FDRCch4RCn_q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import cv2\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF47JY_sNjfI"
      },
      "outputs": [],
      "source": [
        "prompt = \"You are a careful visual annotator. Look only at the image. Decide what kind of scene is shown using the categories below. Be conservative: if unclear, use \\\"scene_type\\\": \\\"other_or_unknown\\\". Output JSON ONLY. \\n\\nScene type options (decide based on visible cues): \\n- combat_or_military_action: Weapons, explosions, airstrikes, armed soldiers in action or at checkpoints. \\n- destruction_or_humanitarian_crisis: Rubble, collapsed buildings, smoke, damaged streets, tents or shelters, refugees, queues for aid, doctors or rescuers helping civilians. \\n- political_or_diplomatic_event: Politicians or officials at podiums or in formal meetings, parliaments, press rooms, negotiation tables, government ceremonies. \\n- news_media_or_interview: TV anchors in a studio, reporters speaking to camera, people being interviewed with a microphone, talk-show or split-screen news formats. \\n- public_protest_or_demonstration: Crowds holding signs or banners, marches, rallies, vigils in streets or squares, police lines facing demonstrators (including protests outside the conflict region). \\n- symbolic_or_religious_ritual: Religious buildings or interiors, prayer, clergy, funerals, coffins, memorials, monuments, candlelight vigils, large flags used in a ceremonial or ritual way. \\n- other_or_unknown: Any scene that does not clearly match the above categories or is too ambiguous. Schema: {\\\"scene_type\\\": [combat_or_military_action|destruction_or_humanitarian_crisis|political_or_diplomatic_event|news_media_or_interview|public_protest_or_demonstration|symbolic_or_religious_ritual|other_or_unknown], text_overlay: present | absent | unknown, evidence: [<=2 short phrases describing visible cues]} If JSON output fails, reprompt with: \\\"Your previous output was invalid. Follow the schema exactly. Output JSON only.\\\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK2Na_fyNWnv"
      },
      "source": [
        "# functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFoReZB5NccW"
      },
      "outputs": [],
      "source": [
        "from ollama import chat\n",
        "import base64\n",
        "from PIL import Image\n",
        "import imageio.v3 as iio\n",
        "model = 'qwen3-vl:4b'\n",
        "\n",
        "def run_ollama_chat(img, prompt):\n",
        "  img_data = iio.imwrite(\"<bytes>\", img, extension='.jpg')\n",
        "\n",
        "\n",
        "  stream = chat(\n",
        "      model=model,\n",
        "      messages=[{'role': 'user', 'content': prompt,\n",
        "        'images': [base64.b64encode(img_data).decode('utf-8')]}],\n",
        "      stream=True,\n",
        "  )\n",
        "  response = \"\"\n",
        "  for chunk in stream:\n",
        "    response += chunk['message']['content']\n",
        "  return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kdFHWlKPsJn"
      },
      "source": [
        "# queries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Uc-NLC7qPyne"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "total = 0\n",
        "\n",
        "for image in os.listdir(\"drive/MyDrive/yt_project/qwen/frames/\"):\n",
        "  images.append(image)\n",
        "  total += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YWRqsioQahz"
      },
      "outputs": [],
      "source": [
        "responses = []\n",
        "x = 1\n",
        "\n",
        "for image in images:\n",
        "  if(len(responses)+1 <= x):\n",
        "    img = iio.imread(\"drive/MyDrive/yt_project/qwen/frames/\" + image)\n",
        "    responses.append(run_ollama_chat(img, prompt))\n",
        "\n",
        "  print(str(x) + \"/\" + str(total))\n",
        "  x += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# compile csv"
      ],
      "metadata": {
        "id": "T5WTf363KeKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id = []\n",
        "video_name = []\n",
        "\n",
        "for outlet in os.listdir(\"drive/MyDrive/yt_project/qwen/videos/\"):\n",
        "  x = 0\n",
        "  for video in os.listdir(\"drive/MyDrive/yt_project/qwen/videos/\" + outlet):\n",
        "    video_name.append(video)\n",
        "    id.append(outlet + str(x))\n",
        "\n",
        "    x += 1\n",
        "\n",
        "video_id = list(zip(video_name, id))"
      ],
      "metadata": {
        "id": "_LCdKDoyHA4J"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_infos = []\n",
        "video_name, id = zip(*video_id)\n",
        "\n",
        "for x in range(len(responses)):\n",
        "  info = []\n",
        "  info.append(video_name[id.index(images[x].split(\"_\")[0])])\n",
        "  info.append(images[x].split(\"_\")[0])\n",
        "  info.append(images[x].split(\"_\")[0] + \"_\" + images[x].split(\"_\")[1])\n",
        "\n",
        "  try:\n",
        "    a = json.loads(responses[x])\n",
        "    info.append(a['scene_type'])\n",
        "    info.append(a['text_overlay'])\n",
        "    info.append(a['evidence'])\n",
        "  except:\n",
        "    info.append([0, 0, 0])\n",
        "\n",
        "  video_infos.append(info)"
      ],
      "metadata": {
        "id": "0IndOEK5G2T1"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(pd.DataFrame(video_infos)).to_csv('bbc_dw_scenes.csv')"
      ],
      "metadata": {
        "id": "BSHsGXzgXx9Q"
      },
      "execution_count": 49,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}